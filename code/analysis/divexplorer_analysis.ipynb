{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "db905f0a",
   "metadata": {},
   "source": [
    "# Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "powered-information",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-20T15:20:44.908897Z",
     "start_time": "2022-04-20T15:20:44.883774Z"
    },
    "id": "powered-information"
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "built-doctor",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-20T15:20:45.349495Z",
     "start_time": "2022-04-20T15:20:44.910825Z"
    },
    "id": "built-doctor"
   },
   "outputs": [],
   "source": [
    "import divexplorer \n",
    "import pandas as pd\n",
    "pd.set_option('max_colwidth', None)\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "from utils_analysis import filter_itemset_df_by_attributes, slice_by_itemset, \\\n",
    "    plot_true_pred, plotComparisonShapleyValues, plotMultipleSV, plotMultipleSV_4, plotShapleyValue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "identical-thirty",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-20T15:20:45.366120Z",
     "start_time": "2022-04-20T15:20:45.351832Z"
    },
    "id": "identical-thirty"
   },
   "outputs": [],
   "source": [
    "## Define the minimum support threshold for data subgroups\n",
    "min_sup = 0.01"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c80058f0",
   "metadata": {},
   "source": [
    "# Util Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c26247e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Function for sorting data cohorts\n",
    "def sortItemset(x, abbreviations={}):\n",
    "    x = list(x)\n",
    "    x.sort()\n",
    "    x = \", \".join(x)\n",
    "    for k, v in abbreviations.items():\n",
    "        x = x.replace(k, v)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e539fc6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def attributes_in_itemset(itemset, attributes, alls = True):\n",
    "    \"\"\" Check if attributes are in the itemset (all or at least one)\n",
    "    \n",
    "    Args:\n",
    "        itemset (frozenset): the itemset\n",
    "        attributes (list): list of itemset of interest\n",
    "        alls (bool): If True, check if ALL attributes of the itemset are the input attributes. \n",
    "        If False, check AT LEAST one attribute of the itemset is in the input attributes.\n",
    "        \n",
    "    \"\"\"\n",
    "    # Avoid returning the empty itemset (i.e., info of entire dataset)\n",
    "    if itemset == frozenset() and attributes:\n",
    "        return False\n",
    "    \n",
    "    for item in itemset:\n",
    "        # Get the attribute\n",
    "        attr_i = item.split(\"=\")[0]\n",
    "        \n",
    "        #If True, check if ALL attributes of the itemset are the input attributes.\n",
    "        if alls:\n",
    "            # Check if the attribute is present. If not, the itemset is not admitted\n",
    "            if attr_i not in attributes:\n",
    "                return False\n",
    "        else:\n",
    "            # Check if least one attribute. If yes, return True\n",
    "            if attr_i in attributes:\n",
    "                return True\n",
    "    if alls:\n",
    "        # All attributes of the itemset are indeed admitted\n",
    "        return True\n",
    "    else:\n",
    "        # Otherwise, it means that we find None\n",
    "        return False\n",
    "    \n",
    "def filter_itemset_df_by_attributes(df: pd.DataFrame, attributes: list, alls = True, itemset_col_name: str = \"itemsets\") -> pd.DataFrame:\n",
    "    \"\"\"Get the set of itemsets that have the attributes in the input list (all or at least one)\n",
    "    \n",
    "    Args:\n",
    "        df (pd.DataFrame): the input itemsets (with their info). \n",
    "        attributes (list): list of itemset of interest\n",
    "        alls (bool): If True, check if ALL attributes of the itemset are the input attributes. \n",
    "        If False, check AT LEAST one attribute of the itemset is in the input attributes.\n",
    "        itemset_col_name (str) : the name of the itemset column, \"itemsets\" as default\n",
    "        \n",
    "    Returns:\n",
    "        pd.DataFrame: the set of itemsets (with their info)\n",
    "    \"\"\"\n",
    "\n",
    "    return df.loc[df[itemset_col_name].apply(lambda x: attributes_in_itemset(x, attributes, alls = alls))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "976dc363",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Define abbreviations for plot and visualization\n",
    "from divexplorer.FP_Divergence import abbreviateDict\n",
    "abbreviations = {'total_silence': 'tot_silence', \\\n",
    "                  'speaker_id' : 'spkID', \\\n",
    "                  'trimmed': 'trim', \\\n",
    "                  'total_':'tot_', \\\n",
    "                  'speed_rate_word_trimmed': 'speakRate_trim', \\\n",
    "                  'trim_duration': 'trim_dur', \\\n",
    "                  'speed_rate_word':'speakRate', \\\n",
    "                  'speed_rate_char':'speakCharRate', \\\n",
    "                  'duration': 'dur'}\n",
    "\n",
    "abbreviations_shorter = abbreviations.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a57ee007",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 3  # Number of subgroups to visualize\n",
    "K = 15  # Global Shapley values to visualize"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "occupational-madrid",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-20T15:07:23.652910Z",
     "start_time": "2022-04-20T15:07:23.612488Z"
    },
    "id": "occupational-madrid"
   },
   "source": [
    "# Define targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "461193a2",
   "metadata": {
    "id": "461193a2"
   },
   "outputs": [],
   "source": [
    "## Target for DivExplorer: 'WER'\n",
    "target_col = 'wer' \n",
    "target_metric = 'd_outcome'\n",
    "target_div = f'd_{target_col}'\n",
    "t_value_col = 't_value_outcome'\n",
    "printable_columns = ['support', 'itemsets', 'wer', 'd_wer', 't_value']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8efa3b44",
   "metadata": {
    "id": "8efa3b44"
   },
   "outputs": [],
   "source": [
    "## Columns for visualization\n",
    "remapped_cols = { \"outcome\": target_col, \"d_outcome\": target_div, t_value_col: 't_value'}\n",
    "show_cols = ['support', 'itemsets', target_col, target_div, 'support_count', 'length', 't_value']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "young-mayor",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-20T15:26:21.281884Z",
     "start_time": "2022-04-20T15:26:21.260270Z"
    },
    "id": "young-mayor"
   },
   "outputs": [],
   "source": [
    "## Columns of the df file that we are going to analyze \n",
    "signal_cols = ['total_duration', 'trimmed_duration', 'n_words', \n",
    "       'speed_rate_word', 'speed_rate_word_trimmed', 'snr', 'spectral_flatness']#, 'total_silence'] \n",
    "       \n",
    "demo_cols = ['speaker_id']\n",
    "\n",
    "input_cols = signal_cols + demo_cols"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "302b8cee",
   "metadata": {},
   "source": [
    "# Retrieve Data and Compute Divergence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9f27c91",
   "metadata": {},
   "outputs": [],
   "source": [
    "from divexplorer.FP_DivergenceExplorer import FP_DivergenceExplorer\n",
    "from divexplorer.FP_Divergence import FP_Divergence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "164157ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "configs = [\n",
    "    \"openai_whisper-base\",\n",
    "    \"openai_whisper-base_en\",\n",
    "    \"openai_whisper-small\",\n",
    "    \"openai_whisper-small_en\",\n",
    "    \"openai_whisper-medium\",\n",
    "    \"openai_whisper-medium_en\",\n",
    "    \"openai_whisper-large-v3\",\n",
    "    \"openai_whisper-base_ft\",\n",
    "    \"openai_whisper-small_ft\",\n",
    "    \"openai_whisper-medium_ft\",\n",
    "    \"openai_whisper-large-v3_ft\",\n",
    "    ]\n",
    "\n",
    "FP_fm_dict = {}\n",
    "fp_divergence_dict = {}\n",
    "df_dict = {}\n",
    "\n",
    "for config in configs:\n",
    "\n",
    "    print(config)\n",
    "\n",
    "    ## Read csv file\n",
    "    if \"ft\" in config:\n",
    "        input_file_divexplorer = os.path.join(\\\n",
    "            os.getcwd(), \"dataframes\", \"fine_tune\", f\"ASR_track2_dev_{config}.csv\")\n",
    "    else:\n",
    "        input_file_divexplorer = os.path.join(\\\n",
    "                os.getcwd(), \"dataframes\", \"zero_shot\", f\"ASR_track2_dev_{config}.csv\") \n",
    "    df = pd.read_csv(input_file_divexplorer, index_col=0)\n",
    "\n",
    "    ## Discretize the dataframe\n",
    "    from util_discretization import discretize\n",
    "\n",
    "    df_discretized = discretize(\n",
    "        df[input_cols+[target_col]],\n",
    "        bins=3,\n",
    "        attributes=input_cols,\n",
    "        strategy=\"quantile\", \n",
    "        round_v = 2,\n",
    "        min_distinct=3,\n",
    "    )\n",
    "    \n",
    "    ## Replace values with ranges: \"low\", \"medium\", \"high\"\n",
    "    replace_values = {}\n",
    "\n",
    "    for i in range(0, len(signal_cols)):\n",
    "        \n",
    "        for v in df_discretized[signal_cols[i]].unique():\n",
    "            if \"<=\" == v[0:2]:\n",
    "                replace_values[v] = \"low\"\n",
    "            elif \">\" == v[0]:\n",
    "                replace_values[v] = \"high\"\n",
    "            elif \"(\"  == v[0] and \"]\"  == v[-1]:\n",
    "                replace_values[v] = \"medium\"\n",
    "            else:\n",
    "                raise ValueError(v)\n",
    "\n",
    "        df_discretized[signal_cols[i]].replace(replace_values, inplace=True)\n",
    "                \n",
    "    ## Create dict of Divergence df\n",
    "    df_dict[config] = df_discretized\n",
    "\n",
    "    fp_diver = FP_DivergenceExplorer(df_discretized, target_name=target_col)\n",
    "    FP_fm = fp_diver.getFrequentPatternDivergence(min_support=min_sup, metrics=[target_metric])\n",
    "        \n",
    "    FP_fm.rename(columns = remapped_cols, inplace = True)\n",
    "    FP_fm = FP_fm[show_cols].copy()\n",
    "    FP_fm['wer'] = round(FP_fm['wer'], 5)\n",
    "    FP_fm['d_wer'] = round(FP_fm['d_wer'], 5)\n",
    "    FP_fm['t_value'] = round(FP_fm['t_value'], 2)\n",
    "    FP_fm_dict[config] = FP_fm\n",
    "    fp_divergence_dict[config] = FP_Divergence(FP_fm, target_div)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7186751",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Compute WER for each config\n",
    "from jiwer import wer\n",
    "\n",
    "for config in configs:\n",
    "\n",
    "        print(config)\n",
    "        \n",
    "        if \"ft\" in config:\n",
    "                input_file_divexplorer = os.path.join(\\\n",
    "                        os.getcwd(), \"dataframes\", \"fine_tune\", f\"ASR_track2_dev_{config}.csv\")\n",
    "        else:\n",
    "                input_file_divexplorer = os.path.join(\\\n",
    "                        os.getcwd(), \"dataframes\", \"zero_shot\", f\"ASR_track2_dev_{config}.csv\") \n",
    "        df = pd.read_csv(input_file_divexplorer, index_col=0)\n",
    "        print(df[target_col].mean())\n",
    "        print(\"-------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb07ca7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "WHISPER_BASE_ZS_WER = 92.457\n",
    "WHISPER_BASE_EN_ZS_WER = 89.997\n",
    "WHISPER_BASE_FT_WER = 77.444\n",
    "\n",
    "WHISPER_SMALL_ZS_WER = 87.446\n",
    "WHISPER_SMALL_EN_ZS_WER = 85.009\n",
    "WHISPER_SMALL_FT_WER = 69.975\n",
    "\n",
    "WHISPER_MEDIUM_ZS_WER = 82.366\n",
    "WHISPER_MEDIUM_EN_ZS_WER = 80.000\n",
    "WHISPER_MEDIUM_FT_WER = 60.028\n",
    "\n",
    "WHISPER_LARGE_ZS_WER = 75.024\n",
    "WHISPER_LARGE_FT_WER = 49.996"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e4341aad",
   "metadata": {},
   "source": [
    "# Divergence Whisper Base"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eff833e3",
   "metadata": {},
   "source": [
    "## Whisper Base (EN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ccb8997",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Compute the divergence for Whisper Base (English)\n",
    "config = 'openai_whisper-base_en'\n",
    "fp_divergence_i = fp_divergence_dict[config]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cca7fd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "\n",
    "## Retrieve Most Divergent Itemsets \n",
    "FPdiv = fp_divergence_i.getDivergence(th_redundancy=0.0)\n",
    "pr = FPdiv.head(n).copy()\n",
    "pr[\"support\"] = pr[\"support\"].round(2)\n",
    "pr[\"wer\"] = (pr[\"wer\"]*100).round(3)\n",
    "pr[\"d_wer\"] = ((pr[\"wer\"] - WHISPER_BASE_EN_ZS_WER)).round(3)\n",
    "pr_l = pr[[ \"itemsets\", \"support\", \"wer\", \"d_wer\", \"t_value\"]].copy()\n",
    "pr_l['itemsets'] = pr_l['itemsets'].apply(lambda x: sortItemset(x, abbreviations))\n",
    "display(pr_l)\n",
    "\n",
    "## Compute Shapley Values for a given itemset\n",
    "if len(pr) > 0:\n",
    "    itemset_1 = pr.iloc[0].itemsets\n",
    "    itemset_shap = fp_divergence_i.computeShapleyValue(itemset_1)\n",
    "    itemset_shap = {k:v*100 for k,v in itemset_shap.items()}\n",
    "    plotShapleyValue(shapley_values=abbreviateDict(itemset_shap, abbreviations), \n",
    "                    sizeFig=(2,2), labelsize=16, titlesize=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56d40846",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Retrieve Top Performing Itemsets \n",
    "FPdiv = fp_divergence_i.getDivergence(th_redundancy=0.0)[::-1] \n",
    "pr = FPdiv.head(n).copy()\n",
    "pr[\"support\"] = pr[\"support\"].round(2)\n",
    "pr[\"wer\"] = (pr[\"wer\"]*100).round(3)\n",
    "pr[\"d_wer\"] = (pr[\"wer\"] - WHISPER_BASE_EN_ZS_WER).round(3)\n",
    "pr_l = pr[[ \"itemsets\", \"support\", \"wer\", \"d_wer\", \"t_value\"]].copy()\n",
    "pr_l['itemsets'] = pr_l['itemsets'].apply(lambda x: sortItemset(x, abbreviations))\n",
    "display(pr_l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cc2fd1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Compute average divergence with std\n",
    "FPdiv = fp_divergence_i.getDivergence(th_redundancy=0.0)\n",
    "pr = FPdiv.copy()\n",
    "pr[\"wer\"] = (pr[\"wer\"]*100).round(3)\n",
    "pr[\"d_wer\"] = ((pr[\"wer\"] - WHISPER_BASE_EN_ZS_WER)).round(3)\n",
    "\n",
    "print(f\"Average WER: {pr['d_wer'].mean()} +/- {pr['d_wer'].std()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c077162",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Individual and Global Divergence\n",
    "# print(\"---------- Individual Divergence ----------\")\n",
    "# individual_divergence = fp_divergence_i.getFItemsetsDivergence()[1]\n",
    "# individual_divergence = {k:v*100 for k,v in individual_divergence.items()}\n",
    "# plotShapleyValue(shapley_values=individual_divergence, \n",
    "#                 sizeFig=(10,10), labelsize=15, titlesize=15)\n",
    "\n",
    "print(\"---------- Global Divergence ----------\")\n",
    "global_item_divergence_whisper_base = fp_divergence_i.computeGlobalShapleyValue()\n",
    "\n",
    "topK_global_whisper_base = {k:v*100 for k,v in global_item_divergence_whisper_base.items() \n",
    "                    if k in sorted(global_item_divergence_whisper_base, \n",
    "                    key=lambda x: abs(global_item_divergence_whisper_base[x]))[::-1][:K]}\n",
    "\n",
    "plotShapleyValue(shapley_values=topK_global_whisper_base, \n",
    "                sizeFig=(10,10), labelsize=22, titlesize=22, \n",
    "                saveFig=True, nameFig=\"gsv_whisper_base_en.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18506f59",
   "metadata": {},
   "source": [
    "## Whisper Base (Multilingual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11b1cd3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Compute the divergence for Whisper Base (Multilingual)\n",
    "config = 'openai_whisper-base'\n",
    "fp_divergence_i = fp_divergence_dict[config]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c08fe6ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "\n",
    "## Retrieve Most Divergent Itemsets \n",
    "FPdiv = fp_divergence_i.getDivergence(th_redundancy=0.0)\n",
    "pr = FPdiv.head(n).copy()\n",
    "pr[\"support\"] = pr[\"support\"].round(2)\n",
    "pr[\"wer\"] = (pr[\"wer\"]*100).round(3)\n",
    "pr[\"d_wer\"] = ((pr[\"wer\"] - WHISPER_BASE_ZS_WER)).round(3)\n",
    "pr_l = pr[[ \"itemsets\", \"support\", \"wer\", \"d_wer\", \"t_value\"]].copy()\n",
    "pr_l['itemsets'] = pr_l['itemsets'].apply(lambda x: sortItemset(x, abbreviations))\n",
    "display(pr_l)\n",
    "\n",
    "## Compute Shapley Values for a given itemset\n",
    "if len(pr) > 0:\n",
    "    itemset_1 = pr.iloc[0].itemsets\n",
    "    itemset_shap = fp_divergence_i.computeShapleyValue(itemset_1)\n",
    "    itemset_shap = {k:v*100 for k,v in itemset_shap.items()}\n",
    "    plotShapleyValue(shapley_values=abbreviateDict(itemset_shap, abbreviations), \n",
    "                    sizeFig=(2,2), labelsize=16, titlesize=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10206575",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Retrieve Top Performing Itemsets \n",
    "FPdiv = fp_divergence_i.getDivergence(th_redundancy=0.0)[::-1] \n",
    "pr = FPdiv.head(n).copy()\n",
    "pr[\"support\"] = pr[\"support\"].round(2)\n",
    "pr[\"wer\"] = (pr[\"wer\"]*100).round(3)\n",
    "pr[\"d_wer\"] = (pr[\"wer\"] - WHISPER_BASE_ZS_WER).round(3)\n",
    "pr_l = pr[[ \"itemsets\", \"support\", \"wer\", \"d_wer\", \"t_value\"]].copy()\n",
    "pr_l['itemsets'] = pr_l['itemsets'].apply(lambda x: sortItemset(x, abbreviations))\n",
    "display(pr_l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ecb8ea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Individual and Global Divergence\n",
    "# print(\"---------- Individual Divergence ----------\")\n",
    "# individual_divergence = fp_divergence_i.getFItemsetsDivergence()[1]\n",
    "# individual_divergence = {k:v*100 for k,v in individual_divergence.items()}\n",
    "# plotShapleyValue(shapley_values=individual_divergence, \n",
    "#                 sizeFig=(10,10), labelsize=15, titlesize=15)\n",
    "\n",
    "print(\"---------- Global Divergence ----------\")\n",
    "global_item_divergence_whisper_base_m = fp_divergence_i.computeGlobalShapleyValue()\n",
    "\n",
    "topK_global_whisper_base_m = {k:v*100 for k,v in global_item_divergence_whisper_base_m.items() \n",
    "                    if k in sorted(global_item_divergence_whisper_base_m, \n",
    "                    key=lambda x: abs(global_item_divergence_whisper_base_m[x]))[::-1][:K]}\n",
    "\n",
    "plotShapleyValue(shapley_values=topK_global_whisper_base_m, \n",
    "                sizeFig=(10,10), labelsize=22, titlesize=22)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "befd6d38",
   "metadata": {},
   "source": [
    "## Whisper Base FT "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41649b0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Compute the divergence for Whisper Base (FT)\n",
    "config = 'openai_whisper-base_ft'\n",
    "fp_divergence_i = fp_divergence_dict[config]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3df7f5c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "\n",
    "## Retrieve Most Divergent Itemsets \n",
    "FPdiv = fp_divergence_i.getDivergence(th_redundancy=0.0)\n",
    "pr = FPdiv.head(n).copy()\n",
    "pr[\"support\"] = pr[\"support\"].round(2)\n",
    "pr[\"wer\"] = (pr[\"wer\"]*100).round(3)\n",
    "pr[\"d_wer\"] = ((pr[\"wer\"] - WHISPER_BASE_FT_WER)).round(3)\n",
    "pr_l = pr[[ \"itemsets\", \"support\", \"wer\", \"d_wer\", \"t_value\"]].copy()\n",
    "pr_l['itemsets'] = pr_l['itemsets'].apply(lambda x: sortItemset(x, abbreviations))\n",
    "display(pr_l)\n",
    "\n",
    "## Compute Shapley Values for a given itemset\n",
    "if len(pr) > 0:\n",
    "    itemset_1 = pr.iloc[0].itemsets\n",
    "    itemset_shap = fp_divergence_i.computeShapleyValue(itemset_1)\n",
    "    itemset_shap = {k:v*100 for k,v in itemset_shap.items()}\n",
    "    plotShapleyValue(shapley_values=abbreviateDict(itemset_shap, abbreviations), \n",
    "                    sizeFig=(2,2), labelsize=16, titlesize=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bed3d57f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Retrieve Top Performing Itemsets \n",
    "FPdiv = fp_divergence_i.getDivergence(th_redundancy=0.0)[::-1] \n",
    "pr = FPdiv.head(n).copy()\n",
    "pr[\"support\"] = pr[\"support\"].round(2)\n",
    "pr[\"wer\"] = (pr[\"wer\"]*100).round(3)\n",
    "pr[\"d_wer\"] = (pr[\"wer\"] - WHISPER_BASE_FT_WER).round(3)\n",
    "pr_l = pr[[ \"itemsets\", \"support\", \"wer\", \"d_wer\", \"t_value\"]].copy()\n",
    "pr_l['itemsets'] = pr_l['itemsets'].apply(lambda x: sortItemset(x, abbreviations))\n",
    "display(pr_l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f18bb443",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Compute average divergence with std\n",
    "FPdiv = fp_divergence_i.getDivergence(th_redundancy=0.0)\n",
    "pr = FPdiv.copy()\n",
    "pr[\"wer\"] = (pr[\"wer\"]*100).round(3)\n",
    "pr[\"d_wer\"] = ((pr[\"wer\"] - WHISPER_BASE_FT_WER)).round(3)\n",
    "\n",
    "print(f\"Average WER: {pr['d_wer'].mean()} +/- {pr['d_wer'].std()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38227edb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Individual and Global Divergence\n",
    "# print(\"---------- Individual Divergence ----------\")\n",
    "# individual_divergence = fp_divergence_i.getFItemsetsDivergence()[1]\n",
    "# individual_divergence = {k:v*100 for k,v in individual_divergence.items()}\n",
    "# plotShapleyValue(shapley_values=individual_divergence, \n",
    "#                 sizeFig=(10,10), labelsize=15, titlesize=15)\n",
    "\n",
    "print(\"---------- Global Divergence ----------\")\n",
    "global_item_divergence_whisper_base_ft = fp_divergence_i.computeGlobalShapleyValue()\n",
    "\n",
    "topK_global_whisper_base_ft = {k:v*100 for k,v in global_item_divergence_whisper_base_ft.items() \n",
    "                    if k in sorted(global_item_divergence_whisper_base_ft, \n",
    "                    key=lambda x: abs(global_item_divergence_whisper_base_ft[x]))[::-1][:K]}\n",
    "\n",
    "plotShapleyValue(shapley_values=topK_global_whisper_base_ft, \n",
    "                sizeFig=(10,10), labelsize=22, titlesize=22)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e4341aad",
   "metadata": {},
   "source": [
    "# Divergence Whisper Small"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efa68cff",
   "metadata": {},
   "source": [
    "## Whisper Small (EN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ccb8997",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Compute the divergence for Whisper Small (English)\n",
    "config = 'openai_whisper-small_en'\n",
    "fp_divergence_i = fp_divergence_dict[config]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cca7fd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "\n",
    "## Retrieve Most Divergent Itemsets \n",
    "FPdiv = fp_divergence_i.getDivergence(th_redundancy=0.0)\n",
    "pr = FPdiv.head(n).copy()\n",
    "pr[\"support\"] = pr[\"support\"].round(2)\n",
    "pr[\"wer\"] = (pr[\"wer\"]*100).round(3)\n",
    "pr[\"d_wer\"] = ((pr[\"wer\"] - WHISPER_SMALL_EN_ZS_WER)).round(3)\n",
    "pr_l = pr[[ \"itemsets\", \"support\", \"wer\", \"d_wer\", \"t_value\"]].copy()\n",
    "pr_l['itemsets'] = pr_l['itemsets'].apply(lambda x: sortItemset(x, abbreviations))\n",
    "display(pr_l)\n",
    "\n",
    "## Compute Shapley Values for a given itemset\n",
    "if len(pr) > 0:\n",
    "    itemset_1 = pr.iloc[0].itemsets\n",
    "    itemset_shap = fp_divergence_i.computeShapleyValue(itemset_1)\n",
    "    itemset_shap = {k:v*100 for k,v in itemset_shap.items()}\n",
    "    plotShapleyValue(shapley_values=abbreviateDict(itemset_shap, abbreviations), \n",
    "                    sizeFig=(2,2), labelsize=16, titlesize=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6ca8d86",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Retrieve Top Performing Itemsets \n",
    "FPdiv = fp_divergence_i.getDivergence(th_redundancy=0.0)[::-1] \n",
    "pr = FPdiv.head(n).copy()\n",
    "pr[\"support\"] = pr[\"support\"].round(2)\n",
    "pr[\"wer\"] = (pr[\"wer\"]*100).round(3)\n",
    "pr[\"d_wer\"] = (pr[\"wer\"] - WHISPER_SMALL_EN_ZS_WER).round(3)\n",
    "pr_l = pr[[ \"itemsets\", \"support\", \"wer\", \"d_wer\", \"t_value\"]].copy()\n",
    "pr_l['itemsets'] = pr_l['itemsets'].apply(lambda x: sortItemset(x, abbreviations))\n",
    "display(pr_l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14bfc1a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Compute average divergence with std\n",
    "FPdiv = fp_divergence_i.getDivergence(th_redundancy=0.0)\n",
    "pr = FPdiv.copy()\n",
    "pr[\"wer\"] = (pr[\"wer\"]*100).round(3)\n",
    "pr[\"d_wer\"] = ((pr[\"wer\"] - WHISPER_SMALL_EN_ZS_WER)).round(3)\n",
    "\n",
    "print(f\"Average WER: {pr['d_wer'].mean()} +/- {pr['d_wer'].std()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4652fb05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Individual and Global Divergence\n",
    "# print(\"---------- Individual Divergence ----------\")\n",
    "# individual_divergence = fp_divergence_i.getFItemsetsDivergence()[1]\n",
    "# individual_divergence = {k:v*100 for k,v in individual_divergence.items()}\n",
    "# plotShapleyValue(shapley_values=individual_divergence, \n",
    "#                 sizeFig=(10,10), labelsize=17, titlesize=17)\n",
    "\n",
    "print(\"---------- Global Divergence ----------\")\n",
    "global_item_divergence_whisper_small = fp_divergence_i.computeGlobalShapleyValue()\n",
    "\n",
    "topK_global_whisper_small = {k:v*100 for k,v in global_item_divergence_whisper_small.items() \n",
    "                    if k in sorted(global_item_divergence_whisper_small, \n",
    "                    key=lambda x: abs(global_item_divergence_whisper_small[x]))[::-1][:K]}\n",
    "\n",
    "plotShapleyValue(shapley_values=topK_global_whisper_small, \n",
    "                sizeFig=(10,10), labelsize=22, titlesize=22)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04a5401f",
   "metadata": {},
   "source": [
    "## Whisper Small (Multilingual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aab6af3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Compute the divergence for Whisper Small (Multilingual)\n",
    "config = 'openai_whisper-small'\n",
    "fp_divergence_i = fp_divergence_dict[config]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd193585",
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "\n",
    "## Retrieve Most Divergent Itemsets \n",
    "FPdiv = fp_divergence_i.getDivergence(th_redundancy=0.0)\n",
    "pr = FPdiv.head(n).copy()\n",
    "pr[\"support\"] = pr[\"support\"].round(2)\n",
    "pr[\"wer\"] = (pr[\"wer\"]*100).round(3)\n",
    "pr[\"d_wer\"] = ((pr[\"wer\"] - WHISPER_SMALL_ZS_WER)).round(3)\n",
    "pr_l = pr[[ \"itemsets\", \"support\", \"wer\", \"d_wer\", \"t_value\"]].copy()\n",
    "pr_l['itemsets'] = pr_l['itemsets'].apply(lambda x: sortItemset(x, abbreviations))\n",
    "display(pr_l)\n",
    "\n",
    "## Compute Shapley Values for a given itemset\n",
    "if len(pr) > 0:\n",
    "    itemset_1 = pr.iloc[0].itemsets\n",
    "    itemset_shap = fp_divergence_i.computeShapleyValue(itemset_1)\n",
    "    itemset_shap = {k:v*100 for k,v in itemset_shap.items()}\n",
    "    plotShapleyValue(shapley_values=abbreviateDict(itemset_shap, abbreviations), \n",
    "                    sizeFig=(2,2), labelsize=16, titlesize=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1da2113",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Retrieve Top Performing Itemsets \n",
    "FPdiv = fp_divergence_i.getDivergence(th_redundancy=0.0)[::-1] \n",
    "pr = FPdiv.head(n).copy()\n",
    "pr[\"support\"] = pr[\"support\"].round(2)\n",
    "pr[\"wer\"] = (pr[\"wer\"]*100).round(3)\n",
    "pr[\"d_wer\"] = (pr[\"wer\"] - WHISPER_SMALL_ZS_WER).round(3)\n",
    "pr_l = pr[[ \"itemsets\", \"support\", \"wer\", \"d_wer\", \"t_value\"]].copy()\n",
    "pr_l['itemsets'] = pr_l['itemsets'].apply(lambda x: sortItemset(x, abbreviations))\n",
    "display(pr_l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b07a97dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Individual and Global Divergence\n",
    "# print(\"---------- Individual Divergence ----------\")\n",
    "# individual_divergence = fp_divergence_i.getFItemsetsDivergence()[1]\n",
    "# individual_divergence = {k:v*100 for k,v in individual_divergence.items()}\n",
    "# plotShapleyValue(shapley_values=individual_divergence, \n",
    "#                 sizeFig=(10,10), labelsize=17, titlesize=17)\n",
    "\n",
    "print(\"---------- Global Divergence ----------\")\n",
    "global_item_divergence_whisper_small_m = fp_divergence_i.computeGlobalShapleyValue()\n",
    "\n",
    "topK_global_whisper_small_m = {k:v*100 for k,v in global_item_divergence_whisper_small_m.items() \n",
    "                    if k in sorted(global_item_divergence_whisper_small_m, \n",
    "                    key=lambda x: abs(global_item_divergence_whisper_small_m[x]))[::-1][:K]}\n",
    "\n",
    "plotShapleyValue(shapley_values=topK_global_whisper_small_m, \n",
    "                sizeFig=(10,10), labelsize=22, titlesize=22)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d08b7f41",
   "metadata": {},
   "source": [
    "## Whisper Small FT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59de8cd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Compute the divergence for Whisper Small (FT)\n",
    "config = 'openai_whisper-small_ft'\n",
    "fp_divergence_i = fp_divergence_dict[config]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b049a122",
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "\n",
    "## Retrieve Most Divergent Itemsets \n",
    "FPdiv = fp_divergence_i.getDivergence(th_redundancy=0.0)\n",
    "pr = FPdiv.head(n).copy()\n",
    "pr[\"support\"] = pr[\"support\"].round(2)\n",
    "pr[\"wer\"] = (pr[\"wer\"]*100).round(3)\n",
    "pr[\"d_wer\"] = ((pr[\"wer\"] - WHISPER_SMALL_FT_WER)).round(3)\n",
    "pr_l = pr[[ \"itemsets\", \"support\", \"wer\", \"d_wer\", \"t_value\"]].copy()\n",
    "pr_l['itemsets'] = pr_l['itemsets'].apply(lambda x: sortItemset(x, abbreviations))\n",
    "display(pr_l)\n",
    "\n",
    "## Compute Shapley Values for a given itemset\n",
    "if len(pr) > 0:\n",
    "    itemset_1 = pr.iloc[0].itemsets\n",
    "    itemset_shap = fp_divergence_i.computeShapleyValue(itemset_1)\n",
    "    itemset_shap = {k:v*100 for k,v in itemset_shap.items()}\n",
    "    plotShapleyValue(shapley_values=abbreviateDict(itemset_shap, abbreviations), \n",
    "                    sizeFig=(2,2), labelsize=16, titlesize=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4ea69b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Retrieve Top Performing Itemsets \n",
    "FPdiv = fp_divergence_i.getDivergence(th_redundancy=0.0)[::-1] \n",
    "pr = FPdiv.head(n).copy()\n",
    "pr[\"support\"] = pr[\"support\"].round(2)\n",
    "pr[\"wer\"] = (pr[\"wer\"]*100).round(3)\n",
    "pr[\"d_wer\"] = (pr[\"wer\"] - WHISPER_SMALL_FT_WER).round(3)\n",
    "pr_l = pr[[ \"itemsets\", \"support\", \"wer\", \"d_wer\", \"t_value\"]].copy()\n",
    "pr_l['itemsets'] = pr_l['itemsets'].apply(lambda x: sortItemset(x, abbreviations))\n",
    "display(pr_l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d9b58c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Compute average divergence with std\n",
    "FPdiv = fp_divergence_i.getDivergence(th_redundancy=0.0)\n",
    "pr = FPdiv.copy()\n",
    "pr[\"wer\"] = (pr[\"wer\"]*100).round(3)\n",
    "pr[\"d_wer\"] = ((pr[\"wer\"] - WHISPER_SMALL_FT_WER)).round(3)\n",
    "\n",
    "print(f\"Average WER: {pr['d_wer'].mean()} +/- {pr['d_wer'].std()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "212d3633",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Individual and Global Divergence\n",
    "# print(\"---------- Individual Divergence ----------\")\n",
    "# individual_divergence = fp_divergence_i.getFItemsetsDivergence()[1]\n",
    "# individual_divergence = {k:v*100 for k,v in individual_divergence.items()}\n",
    "# plotShapleyValue(shapley_values=individual_divergence, \n",
    "#                 sizeFig=(10,10), labelsize=17, titlesize=17)\n",
    "\n",
    "print(\"---------- Global Divergence ----------\")\n",
    "global_item_divergence_whisper_small_m_ft = fp_divergence_i.computeGlobalShapleyValue()\n",
    "\n",
    "topK_global_whisper_small_m_ft = {k:v*100 for k,v in global_item_divergence_whisper_small_m_ft.items() \n",
    "                    if k in sorted(global_item_divergence_whisper_small_m_ft, \n",
    "                    key=lambda x: abs(global_item_divergence_whisper_small_m_ft[x]))[::-1][:K]}\n",
    "\n",
    "plotShapleyValue(shapley_values=topK_global_whisper_small_m_ft, \n",
    "                sizeFig=(10,10), labelsize=22, titlesize=22)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e4341aad",
   "metadata": {},
   "source": [
    "# Divergence Whisper Medium"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebc793f5",
   "metadata": {},
   "source": [
    "## Whisper Medium (EN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ccb8997",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Compute the divergence for Whisper Medium (EN)\n",
    "config = 'openai_whisper-medium_en'\n",
    "fp_divergence_i = fp_divergence_dict[config]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e72e1aaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "\n",
    "## Retrieve Most Divergent Itemsets \n",
    "FPdiv = fp_divergence_i.getDivergence(th_redundancy=0.0)\n",
    "pr = FPdiv.head(n).copy()\n",
    "pr[\"support\"] = pr[\"support\"].round(2)\n",
    "pr[\"wer\"] = (pr[\"wer\"]*100).round(3)\n",
    "pr[\"d_wer\"] = ((pr[\"wer\"] - WHISPER_MEDIUM_EN_ZS_WER)).round(3)\n",
    "pr_l = pr[[ \"itemsets\", \"support\", \"wer\", \"d_wer\", \"t_value\"]].copy()\n",
    "pr_l['itemsets'] = pr_l['itemsets'].apply(lambda x: sortItemset(x, abbreviations))\n",
    "display(pr_l)\n",
    "\n",
    "## Compute Shapley Values for a given itemset\n",
    "if len(pr) > 0:\n",
    "    itemset_1 = pr.iloc[0].itemsets\n",
    "    itemset_shap = fp_divergence_i.computeShapleyValue(itemset_1)\n",
    "    itemset_shap = {k:v*100 for k,v in itemset_shap.items()}\n",
    "    plotShapleyValue(shapley_values=abbreviateDict(itemset_shap, abbreviations), \n",
    "                    sizeFig=(2,2), labelsize=16, titlesize=16, \n",
    "                    saveFig=True, nameFig=\"shapley_values_whisper_medium_en_negative.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6179c809",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Retrieve Top Performing Itemsets \n",
    "FPdiv = fp_divergence_i.getDivergence(th_redundancy=0.0)[::-1] \n",
    "pr = FPdiv.head(n).copy()\n",
    "pr[\"support\"] = pr[\"support\"].round(2)\n",
    "pr[\"wer\"] = (pr[\"wer\"]*100).round(3)\n",
    "pr[\"d_wer\"] = (pr[\"wer\"] - WHISPER_MEDIUM_EN_ZS_WER).round(3)\n",
    "pr_l = pr[[ \"itemsets\", \"support\", \"wer\", \"d_wer\", \"t_value\"]].copy()\n",
    "pr_l['itemsets'] = pr_l['itemsets'].apply(lambda x: sortItemset(x, abbreviations))\n",
    "display(pr_l)\n",
    "\n",
    "## Compute Shapley Values for a given itemset\n",
    "if len(pr) > 0:\n",
    "    itemset_1 = pr.iloc[0].itemsets\n",
    "    itemset_shap = fp_divergence_i.computeShapleyValue(itemset_1)\n",
    "    itemset_shap = {k:v*100 for k,v in itemset_shap.items()}\n",
    "    plotShapleyValue(shapley_values=abbreviateDict(itemset_shap, abbreviations), \n",
    "                    sizeFig=(2,2), labelsize=16, titlesize=16, negative=True,\n",
    "                    saveFig=True, nameFig=\"shapley_values_whisper_medium_en_positive.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b71121f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Compute average divergence with std\n",
    "FPdiv = fp_divergence_i.getDivergence(th_redundancy=0.0)\n",
    "pr = FPdiv.copy()\n",
    "pr[\"wer\"] = (pr[\"wer\"]*100).round(3)\n",
    "pr[\"d_wer\"] = ((pr[\"wer\"] - WHISPER_MEDIUM_EN_ZS_WER)).round(3)\n",
    "\n",
    "print(f\"Average WER: {pr['d_wer'].mean()} +/- {pr['d_wer'].std()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6613b023",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Individual and Global Divergence\n",
    "# print(\"---------- Individual Divergence ----------\")\n",
    "# individual_divergence = fp_divergence_i.getFItemsetsDivergence()[1]\n",
    "# individual_divergence = {k:v*100 for k,v in individual_divergence.items()}\n",
    "# plotShapleyValue(shapley_values=individual_divergence, \n",
    "#                 sizeFig=(10,10), labelsize=17, titlesize=17)\n",
    "\n",
    "print(\"---------- Global Divergence ----------\")\n",
    "global_item_divergence_whisper_medium = fp_divergence_i.computeGlobalShapleyValue()\n",
    "\n",
    "topK_global_whisper_medium = {k:v*100 for k,v in global_item_divergence_whisper_medium.items() \n",
    "                    if k in sorted(global_item_divergence_whisper_medium, \n",
    "                    key=lambda x: abs(global_item_divergence_whisper_medium[x]))[::-1][:K]}\n",
    "\n",
    "plotShapleyValue(shapley_values=topK_global_whisper_medium, \n",
    "                sizeFig=(10,10), labelsize=22, titlesize=22)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2280b3f9",
   "metadata": {},
   "source": [
    "## Whisper Medium (Multilingual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cfa6fdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Compute the divergence for Whisper Medium (Multilingual)\n",
    "config = 'openai_whisper-medium'\n",
    "fp_divergence_i = fp_divergence_dict[config]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa53eae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "\n",
    "## Retrieve Most Divergent Itemsets \n",
    "FPdiv = fp_divergence_i.getDivergence(th_redundancy=0.0)\n",
    "pr = FPdiv.head(n).copy()\n",
    "pr[\"support\"] = pr[\"support\"].round(2)\n",
    "pr[\"wer\"] = (pr[\"wer\"]*100).round(3)\n",
    "pr[\"d_wer\"] = ((pr[\"wer\"] - WHISPER_MEDIUM_ZS_WER)).round(3)\n",
    "pr_l = pr[[ \"itemsets\", \"support\", \"wer\", \"d_wer\", \"t_value\"]].copy()\n",
    "pr_l['itemsets'] = pr_l['itemsets'].apply(lambda x: sortItemset(x, abbreviations))\n",
    "display(pr_l)\n",
    "\n",
    "## Compute Shapley Values for a given itemset\n",
    "if len(pr) > 0:\n",
    "    itemset_1 = pr.iloc[0].itemsets\n",
    "    itemset_shap = fp_divergence_i.computeShapleyValue(itemset_1)\n",
    "    itemset_shap = {k:v*100 for k,v in itemset_shap.items()}\n",
    "    plotShapleyValue(shapley_values=abbreviateDict(itemset_shap, abbreviations), \n",
    "                    sizeFig=(2,2), labelsize=16, titlesize=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9749745f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Retrieve Top Performing Itemsets \n",
    "FPdiv = fp_divergence_i.getDivergence(th_redundancy=0.0)[::-1] \n",
    "pr = FPdiv.head(n).copy()\n",
    "pr[\"support\"] = pr[\"support\"].round(2)\n",
    "pr[\"wer\"] = (pr[\"wer\"]*100).round(3)\n",
    "pr[\"d_wer\"] = (pr[\"wer\"] - WHISPER_MEDIUM_ZS_WER).round(3)\n",
    "pr_l = pr[[ \"itemsets\", \"support\", \"wer\", \"d_wer\", \"t_value\"]].copy()\n",
    "pr_l['itemsets'] = pr_l['itemsets'].apply(lambda x: sortItemset(x, abbreviations))\n",
    "display(pr_l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecda8e42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Individual and Global Divergence\n",
    "# print(\"---------- Individual Divergence ----------\")\n",
    "# individual_divergence = fp_divergence_i.getFItemsetsDivergence()[1]\n",
    "# individual_divergence = {k:v*100 for k,v in individual_divergence.items()}\n",
    "# plotShapleyValue(shapley_values=individual_divergence, \n",
    "#                 sizeFig=(10,10), labelsize=17, titlesize=17)\n",
    "\n",
    "print(\"---------- Global Divergence ----------\")\n",
    "global_item_divergence_whisper_medium_m = fp_divergence_i.computeGlobalShapleyValue()\n",
    "\n",
    "topK_global_whisper_medium_ = {k:v*100 for k,v in global_item_divergence_whisper_medium_m.items() \n",
    "                    if k in sorted(global_item_divergence_whisper_medium_m, \n",
    "                    key=lambda x: abs(global_item_divergence_whisper_medium_m[x]))[::-1][:K]}\n",
    "\n",
    "plotShapleyValue(shapley_values=topK_global_whisper_medium_, \n",
    "                sizeFig=(10,10), labelsize=22, titlesize=22)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5876d4c0",
   "metadata": {},
   "source": [
    "## Whisper Medium FT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0368f6df",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Compute the divergence for Whisper Medium (FT)\n",
    "config = 'openai_whisper-medium_ft'\n",
    "fp_divergence_i = fp_divergence_dict[config]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f37632e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "\n",
    "## Retrieve Most Divergent Itemsets \n",
    "FPdiv = fp_divergence_i.getDivergence(th_redundancy=0.0)\n",
    "pr = FPdiv.head(n).copy()\n",
    "pr[\"support\"] = pr[\"support\"].round(2)\n",
    "pr[\"wer\"] = (pr[\"wer\"]*100).round(3)\n",
    "pr[\"d_wer\"] = ((pr[\"wer\"] - WHISPER_MEDIUM_FT_WER)).round(3)\n",
    "pr_l = pr[[ \"itemsets\", \"support\", \"wer\", \"d_wer\", \"t_value\"]].copy()\n",
    "pr_l['itemsets'] = pr_l['itemsets'].apply(lambda x: sortItemset(x, abbreviations))\n",
    "display(pr_l)\n",
    "\n",
    "## Compute Shapley Values for a given itemset\n",
    "if len(pr) > 0:\n",
    "    itemset_1 = pr.iloc[0].itemsets\n",
    "    itemset_shap = fp_divergence_i.computeShapleyValue(itemset_1)\n",
    "    itemset_shap = {k:v*100 for k,v in itemset_shap.items()}\n",
    "    plotShapleyValue(shapley_values=abbreviateDict(itemset_shap, abbreviations), \n",
    "                    sizeFig=(2,2), labelsize=16, titlesize=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ac229c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Retrieve Top Performing Itemsets \n",
    "FPdiv = fp_divergence_i.getDivergence(th_redundancy=0.0)[::-1] \n",
    "pr = FPdiv.head(n).copy()\n",
    "pr[\"support\"] = pr[\"support\"].round(2)\n",
    "pr[\"wer\"] = (pr[\"wer\"]*100).round(3)\n",
    "pr[\"d_wer\"] = (pr[\"wer\"] - WHISPER_MEDIUM_FT_WER).round(3)\n",
    "pr_l = pr[[ \"itemsets\", \"support\", \"wer\", \"d_wer\", \"t_value\"]].copy()\n",
    "pr_l['itemsets'] = pr_l['itemsets'].apply(lambda x: sortItemset(x, abbreviations))\n",
    "display(pr_l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad2f66ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Compute average divergence with std\n",
    "FPdiv = fp_divergence_i.getDivergence(th_redundancy=0.0)\n",
    "pr = FPdiv.copy()\n",
    "pr[\"wer\"] = (pr[\"wer\"]*100).round(3)\n",
    "pr[\"d_wer\"] = ((pr[\"wer\"] - WHISPER_MEDIUM_FT_WER)).round(3)\n",
    "\n",
    "print(f\"Average WER: {pr['d_wer'].mean()} +/- {pr['d_wer'].std()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee568cbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Individual and Global Divergence\n",
    "# print(\"---------- Individual Divergence ----------\")\n",
    "# individual_divergence = fp_divergence_i.getFItemsetsDivergence()[1]\n",
    "# individual_divergence = {k:v*100 for k,v in individual_divergence.items()}\n",
    "# plotShapleyValue(shapley_values=individual_divergence, \n",
    "#                 sizeFig=(10,10), labelsize=17, titlesize=17)\n",
    "\n",
    "print(\"---------- Global Divergence ----------\")\n",
    "global_item_divergence_whisper_medium_ft = fp_divergence_i.computeGlobalShapleyValue()\n",
    "\n",
    "topK_global_whisper_medium_ft = {k:v*100 for k,v in global_item_divergence_whisper_medium_ft.items() \n",
    "                    if k in sorted(global_item_divergence_whisper_medium_ft, \n",
    "                    key=lambda x: abs(global_item_divergence_whisper_medium_ft[x]))[::-1][:K]}\n",
    "\n",
    "plotShapleyValue(shapley_values=topK_global_whisper_medium_ft, \n",
    "                sizeFig=(10,10), labelsize=22, titlesize=22)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e4341aad",
   "metadata": {},
   "source": [
    "# Divergence Whisper Large"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "527ea429",
   "metadata": {},
   "source": [
    "## Whisper Large (Multilingual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ccb8997",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Compute the divergence for Whisper Large\n",
    "config = 'openai_whisper-large-v3'\n",
    "fp_divergence_i = fp_divergence_dict[config]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cca7fd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "\n",
    "## Retrieve Most Divergent Itemsets \n",
    "FPdiv = fp_divergence_i.getDivergence(th_redundancy=0.0)\n",
    "pr = FPdiv.head(n).copy()\n",
    "pr[\"support\"] = pr[\"support\"].round(2)\n",
    "pr[\"wer\"] = (pr[\"wer\"]*100).round(3)\n",
    "pr[\"d_wer\"] = ((pr[\"wer\"] - WHISPER_LARGE_ZS_WER)).round(3)\n",
    "pr_l = pr[[ \"itemsets\", \"support\", \"wer\", \"d_wer\", \"t_value\"]].copy()\n",
    "pr_l['itemsets'] = pr_l['itemsets'].apply(lambda x: sortItemset(x, abbreviations))\n",
    "display(pr_l)\n",
    "\n",
    "## Compute Shapley Values for a given itemset\n",
    "if len(pr) > 0:\n",
    "    itemset_1 = pr.iloc[0].itemsets\n",
    "    itemset_shap = fp_divergence_i.computeShapleyValue(itemset_1)\n",
    "    itemset_shap = {k:v*100 for k,v in itemset_shap.items()}\n",
    "    plotShapleyValue(shapley_values=abbreviateDict(itemset_shap, abbreviations), \n",
    "                    sizeFig=(2,2), labelsize=16, titlesize=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ce5d080",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Retrieve Top Performing Itemsets \n",
    "FPdiv = fp_divergence_i.getDivergence(th_redundancy=0.0)[::-1] \n",
    "pr = FPdiv.head(n).copy()\n",
    "pr[\"support\"] = pr[\"support\"].round(2)\n",
    "pr[\"wer\"] = (pr[\"wer\"]*100).round(3)\n",
    "pr[\"d_wer\"] = (pr[\"wer\"] - WHISPER_LARGE_ZS_WER).round(3)\n",
    "pr_l = pr[[ \"itemsets\", \"support\", \"wer\", \"d_wer\", \"t_value\"]].copy()\n",
    "pr_l['itemsets'] = pr_l['itemsets'].apply(lambda x: sortItemset(x, abbreviations))\n",
    "display(pr_l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dedba98",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Compute average divergence with std\n",
    "FPdiv = fp_divergence_i.getDivergence(th_redundancy=0.0)\n",
    "pr = FPdiv.copy()\n",
    "pr[\"wer\"] = (pr[\"wer\"]*100).round(3)\n",
    "pr[\"d_wer\"] = ((pr[\"wer\"] - WHISPER_LARGE_ZS_WER)).round(3)\n",
    "\n",
    "print(f\"Average WER: {pr['d_wer'].mean()} +/- {pr['d_wer'].std()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb2a71cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Individual and Global Divergence\n",
    "# print(\"---------- Individual Divergence ----------\")\n",
    "# individual_divergence = fp_divergence_i.getFItemsetsDivergence()[1]\n",
    "# individual_divergence = {k:v*100 for k,v in individual_divergence.items()}\n",
    "# plotShapleyValue(shapley_values=individual_divergence, \n",
    "#                 sizeFig=(10,10), labelsize=17, titlesize=17)\n",
    "\n",
    "print(\"---------- Global Divergence ----------\")\n",
    "global_item_divergence_whisperl = fp_divergence_i.computeGlobalShapleyValue()\n",
    "\n",
    "topK_global_whisperl = {k:v*100 for k,v in global_item_divergence_whisperl.items() \n",
    "                    if k in sorted(global_item_divergence_whisperl, \n",
    "                    key=lambda x: abs(global_item_divergence_whisperl[x]))[::-1][:K]}\n",
    "\n",
    "plotShapleyValue(shapley_values=topK_global_whisperl, \n",
    "                sizeFig=(10,10),labelsize=22, titlesize=22)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56de100b",
   "metadata": {},
   "source": [
    "## Whisper Large FT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d73201e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Compute the divergence for Whisper Large (FT)\n",
    "config = 'openai_whisper-large-v3_ft'\n",
    "fp_divergence_i = fp_divergence_dict[config]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c7e47d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "\n",
    "## Retrieve Most Divergent Itemsets \n",
    "FPdiv = fp_divergence_i.getDivergence(th_redundancy=0.0)\n",
    "pr = FPdiv.head(n).copy()\n",
    "pr[\"support\"] = pr[\"support\"].round(2)\n",
    "pr[\"wer\"] = (pr[\"wer\"]*100).round(3)\n",
    "pr[\"d_wer\"] = ((pr[\"wer\"] - WHISPER_LARGE_FT_WER)).round(3)\n",
    "pr_l = pr[[ \"itemsets\", \"support\", \"wer\", \"d_wer\", \"t_value\"]].copy()\n",
    "pr_l['itemsets'] = pr_l['itemsets'].apply(lambda x: sortItemset(x, abbreviations))\n",
    "display(pr_l)\n",
    "\n",
    "## Compute Shapley Values for a given itemset\n",
    "if len(pr) > 0:\n",
    "    itemset_1 = pr.iloc[0].itemsets\n",
    "    itemset_shap = fp_divergence_i.computeShapleyValue(itemset_1)\n",
    "    itemset_shap = {k:v*100 for k,v in itemset_shap.items()}\n",
    "    plotShapleyValue(shapley_values=abbreviateDict(itemset_shap, abbreviations), \n",
    "                    sizeFig=(2,2), labelsize=16, titlesize=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16cd830e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Retrieve Top Performing Itemsets \n",
    "FPdiv = fp_divergence_i.getDivergence(th_redundancy=0.0)[::-1] \n",
    "pr = FPdiv.head(n).copy()\n",
    "pr[\"support\"] = pr[\"support\"].round(2)\n",
    "pr[\"wer\"] = (pr[\"wer\"]*100).round(3)\n",
    "pr[\"d_wer\"] = (pr[\"wer\"] - WHISPER_LARGE_FT_WER).round(3)\n",
    "pr_l = pr[[ \"itemsets\", \"support\", \"wer\", \"d_wer\", \"t_value\"]].copy()\n",
    "pr_l['itemsets'] = pr_l['itemsets'].apply(lambda x: sortItemset(x, abbreviations))\n",
    "display(pr_l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31ee87ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Compute average divergence with std\n",
    "FPdiv = fp_divergence_i.getDivergence(th_redundancy=0.0)\n",
    "pr = FPdiv.copy()\n",
    "pr[\"wer\"] = (pr[\"wer\"]*100).round(3)\n",
    "pr[\"d_wer\"] = ((pr[\"wer\"] - WHISPER_LARGE_FT_WER)).round(3)\n",
    "\n",
    "print(f\"Average WER: {pr['d_wer'].mean()} +/- {pr['d_wer'].std()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a61fcad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Individual and Global Divergence\n",
    "# print(\"---------- Individual Divergence ----------\")\n",
    "# individual_divergence = fp_divergence_i.getFItemsetsDivergence()[1]\n",
    "# individual_divergence = {k:v*100 for k,v in individual_divergence.items()}\n",
    "# plotShapleyValue(shapley_values=individual_divergence, \n",
    "#                 sizeFig=(10,10), labelsize=17, titlesize=17)\n",
    "\n",
    "print(\"---------- Global Divergence ----------\")\n",
    "global_item_divergence_whisperl_ft = fp_divergence_i.computeGlobalShapleyValue()\n",
    "\n",
    "topK_global_whisperl_ft = {k:v*100 for k,v in global_item_divergence_whisperl_ft.items() \n",
    "                    if k in sorted(global_item_divergence_whisperl_ft, \n",
    "                    key=lambda x: abs(global_item_divergence_whisperl_ft[x]))[::-1][:K]}\n",
    "\n",
    "plotShapleyValue(shapley_values=topK_global_whisperl_ft, \n",
    "                sizeFig=(10,10),labelsize=22, titlesize=22)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0ba25022",
   "metadata": {},
   "source": [
    "# Divergence difference Whisper Base vs Whisper Large"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc56bafe",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Compute the divergence for Whisper Large-v3\n",
    "config = 'openai_whisper-small'\n",
    "fp_divergence_i = fp_divergence_dict[config]\n",
    "FPdiv_wl = fp_divergence_i.getDivergence(th_redundancy=None).copy()\n",
    "wlarge = FPdiv_wl.set_index(\"itemsets\")\n",
    "\n",
    "## Compute the divergence for Whisper Base EN\n",
    "config = 'openai_whisper-base_en'\n",
    "fp_divergence_i = fp_divergence_dict[config]\n",
    "FPdiv_wb = fp_divergence_i.getDivergence(th_redundancy=None).copy()\n",
    "wbase = FPdiv_wb.set_index(\"itemsets\")\n",
    "\n",
    "## Merge the df\n",
    "merged = wbase.join(wlarge, lsuffix='_base', rsuffix='_large')\n",
    "merged = merged.rename(columns={'support_large': 'support'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32256e51",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Compute difference in performance between the models\n",
    "diff = \"d_difference\"\n",
    "merged[diff] = merged[\"wer_large\"] - merged[\"wer_base\"]\n",
    "merged[\"difference\"] = merged[\"wer_large\"] - merged[\"wer_base\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c799c4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create \"Gain Base-Large Whisper\" df and compute divergence\n",
    "base_large_gain_df = merged[['support', 'wer_large', 'd_wer_large', 't_value_large', \\\n",
    "       'support_count_large', 'length_large', 't_value_large'] \\\n",
    "       + [diff, \"difference\", \"wer_base\", \"t_value_base\"]]\n",
    "base_large_gain_df = base_large_gain_df.rename(columns={'length_large':'length'})\n",
    "base_large_gain_df = base_large_gain_df.reset_index()\n",
    "\n",
    "fp_divergence_difference = FP_Divergence(base_large_gain_df, diff)\n",
    "diff_nr = fp_divergence_difference.getDivergence(th_redundancy=0.0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5981f5a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Select meaningful columns \n",
    "sel = diff_nr.itemsets.values\n",
    "compare_performance = merged.loc[sel].sort_values(diff, ascending = False)\n",
    "cols = ['d_difference', 'wer_base', 'wer_large', 'support', 't_value_base', 't_value_large']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "008980f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "## plot the distribution of the gain in performance\n",
    "list_diff_pos = list(compare_performance[compare_performance['d_difference'] <= 0.0].d_difference)\n",
    "list_diff_pos = [i * 100 for i in list_diff_pos]\n",
    "fig, ax = plt.subplots(figsize=(6, 4))\n",
    "sns.histplot(list_diff_pos, bins=10, kde=False, ax=ax, color='C01', palette=\"colorblind\")\n",
    "list_diff_neg = list(compare_performance[compare_performance['d_difference'] >= 0.0].d_difference)\n",
    "list_diff_neg = [i * 100 for i in list_diff_neg]\n",
    "sns.histplot(list_diff_neg, bins=2, kde=False, ax=ax, color='#83C4FA', palette=\"colorblind\")\n",
    "\n",
    "ax.set_xlabel(\"Gap in performance\", fontsize=28)\n",
    "ax.set_ylabel(r\"# Subgroups\", fontsize=28)\n",
    "plt.xticks(fontsize=20)\n",
    "plt.yticks(fontsize=20)\n",
    "plt.tight_layout()\n",
    "# plt.savefig(\"distribution_gain_whisper_base_large.pdf\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c7560518",
   "metadata": {},
   "source": [
    "## Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a76357a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Compute meaningful statistics:\n",
    "diff_nr_0 = fp_divergence_difference.getDivergence(th_redundancy=None)\n",
    "\n",
    "# Percentage of itemsets for which performance are equal for the two model\n",
    "print(\"Equal\")\n",
    "print(round(100*(diff_nr_0.loc[(diff_nr_0[diff])==0].shape[0]/diff_nr_0.shape[0]),10))\n",
    "\n",
    "# Percentage of itemsets for which performance are lower for Whisper Large\n",
    "# (The higher the WER the lower the performance)\n",
    "print(\"Greater\")\n",
    "print(round(100*(diff_nr_0.loc[(diff_nr_0[diff])>0].shape[0]/diff_nr_0.shape[0]), 10))\n",
    "greater = False if round(100*(diff_nr_0.loc[(diff_nr_0[diff])>0].shape[0]/diff_nr_0.shape[0]), 10) == 0.0 else True\n",
    "    \n",
    "# Percentage of itemsets for which performance are greater for Whisper Large\n",
    "# (The lower the WER the greater the performance)\n",
    "print(\"Lower\")\n",
    "print(round(100*(diff_nr_0.loc[(diff_nr_0[diff])<0].shape[0]/diff_nr_0.shape[0]), 10))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "01d0c446",
   "metadata": {},
   "source": [
    "## Gain > 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d4c0e17",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Retrieve the data cohorts for which Whisper Large performs worse than Whisper Base\n",
    "pr = compare_performance[cols].head(20).reset_index()\n",
    "pr[\"support\"] = pr[\"support\"].round(2)\n",
    "pr[\"wer_large\"] = (pr[\"wer_large\"]*100).round(2)\n",
    "pr[\"wer_base\"] = (pr[\"wer_base\"]*100).round(2)\n",
    "pr[\"d_difference\"] = (pr[\"d_difference\"]*100).round(2)\n",
    "\n",
    "## Abbreviate itemset names for better visualization\n",
    "pr_l = pr.head(2).copy()\n",
    "pr_l['itemsets'] = pr_l['itemsets'].apply(lambda x: sortItemset(x, abbreviations))\n",
    "pr_l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d4d940c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Compute Shapley Values for a given itemset\n",
    "if greater and len(pr) > 0:\n",
    "    itemset_1 = pr.iloc[1].itemsets\n",
    "    itemset_shap = fp_divergence_difference.computeShapleyValue(itemset_1)\n",
    "    itemset_shap = {k:v*100 for k,v in itemset_shap.items()}\n",
    "    plotShapleyValue(shapley_values=abbreviateDict(itemset_shap, abbreviations), \n",
    "                    sizeFig=(2,2), labelsize=16, titlesize=16)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b4b34610",
   "metadata": {},
   "source": [
    "## Gain < 0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ac034d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Retrieve the data cohorts for which Whisper Large performs better than Whisper Base\n",
    "pr = compare_performance[cols][::-1].head(20).reset_index()\n",
    "pr[\"support\"] = pr[\"support\"].round(2)\n",
    "pr[\"wer_large\"] = (pr[\"wer_large\"]*100).round(2)\n",
    "pr[\"wer_base\"] = (pr[\"wer_base\"]*100).round(2)\n",
    "pr[\"d_difference\"] = (pr[\"d_difference\"]*100).round(2)\n",
    "\n",
    "## Abbreviate itemset names for better visualization\n",
    "pr_l = pr.head(2).copy()\n",
    "pr_l['itemsets'] = pr_l['itemsets'].apply(lambda x: sortItemset(x, abbreviations))\n",
    "pr_l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96b57661",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Compute Shapley Values for a given itemset\n",
    "if len(pr) > 0:\n",
    "    itemset_1 = pr.iloc[0].itemsets\n",
    "    itemset_shap = fp_divergence_difference.computeShapleyValue(itemset_1)\n",
    "    itemset_shap = {k:v*100 for k,v in itemset_shap.items()}\n",
    "    plotShapleyValue(shapley_values=abbreviateDict(itemset_shap, abbreviations), \n",
    "                    sizeFig=(2,2), labelsize=16, titlesize=16)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5a566eb0",
   "metadata": {},
   "source": [
    "## Gain = 0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6fb950a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Retrieve the data cohorts for which Whisper Large performs equal to Whisper Base\n",
    "pr = merged.loc[ fp_divergence_difference.getDivergence(th_redundancy=0.0).itemsets.values][cols].reset_index()\n",
    "pr[\"support_large\"] = pr[\"support\"].round(2)\n",
    "pr[\"wer_large\"] = (pr[\"wer_large\"]*100).round(2)\n",
    "pr[\"wer_base\"] = (pr[\"wer_base\"]*100).round(2)\n",
    "pr[\"d_difference\"] = (pr[\"d_difference\"]*100).round(2)\n",
    "pr = pr.loc[abs(pr[\"d_difference\"])==0]\n",
    "pr = pr.sort_values(\"wer_large\").sort_values(\"wer_large\")\n",
    "\n",
    "## Abbreviate itemset names for better visualization\n",
    "pr_l = pr.head(2).copy()\n",
    "pr_l['itemsets'] = pr_l['itemsets'].apply(lambda x: sortItemset(x, abbreviations))\n",
    "pr_l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d17cfdc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Compute Shapley Values for a given itemset\n",
    "if len(pr) > 0:\n",
    "    itemset_1 = pr.iloc[0].itemsets\n",
    "    itemset_shap = fp_divergence_difference.computeShapleyValue(itemset_1)\n",
    "    itemset_shap = {k:v*100 for k,v in itemset_shap.items()}\n",
    "    plotShapleyValue(shapley_values=abbreviateDict(itemset_shap, abbreviations), \n",
    "                    sizeFig=(2,2), labelsize=16, titlesize=16)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e6463273",
   "metadata": {},
   "source": [
    "## Global Shapley value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f110edc",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Compute the top-K global shapley values related to the gain in performance between Whisper Base and Whisper Large\n",
    "global_item_divergence_wb_wl = fp_divergence_difference.computeGlobalShapleyValue()\n",
    "\n",
    "K = 15\n",
    "topK_global_wb_wl = {k:v for k,v in global_item_divergence_wb_wl.items() \\\n",
    "                        if k in sorted(global_item_divergence_wb_wl, \n",
    "                        key=lambda x: abs(global_item_divergence_wb_wl[x]))[::-1][:K]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2f0a189",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "## Plot and Save the image \n",
    "sizeFig = (3.2,4)\n",
    "labelsize = 16\n",
    "titlesize = 16\n",
    "\n",
    "topK_global_wb_wl_abbr = abbreviateDict(topK_global_wb_wl, abbreviations)\n",
    "topK_global_wb_wl_abbr = {k:v*100 for k,v in topK_global_wb_wl_abbr.items()}\n",
    "name_fig = \"global_shapley_gain_wb_wl.pdf\"\n",
    "plotShapleyValue(shapley_values=topK_global_wb_wl_abbr, \\\n",
    "                sizeFig=sizeFig, labelsize=labelsize, titlesize=titlesize, \\\n",
    "                title=r\"$\\tilde{\\Delta}^g_{gain} WhisperB - WhisperL$\",\n",
    "                nameFig=name_fig, saveFig=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7766bd2b",
   "metadata": {},
   "source": [
    "# Divergence difference Whisper Base vs Whisper Base ft."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b5da517",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Compute the divergence for Whisper Base Ft\n",
    "config = 'openai_whisper-large-v3_ft'\n",
    "fp_divergence_i = fp_divergence_dict[config]\n",
    "FPdiv_wl = fp_divergence_i.getDivergence(th_redundancy=None).copy()\n",
    "wbase_ft = FPdiv_wl.set_index(\"itemsets\")\n",
    "\n",
    "## Compute the divergence for Whisper Base EN\n",
    "config = 'openai_whisper-large-v3'\n",
    "fp_divergence_i = fp_divergence_dict[config]\n",
    "FPdiv_wb = fp_divergence_i.getDivergence(th_redundancy=None).copy()\n",
    "wbase = FPdiv_wb.set_index(\"itemsets\")\n",
    "\n",
    "## Merge the df\n",
    "merged = wbase.join(wbase_ft, lsuffix='_base', rsuffix='_base_ft')\n",
    "merged = merged.rename(columns={'support_base_ft': 'support'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dbb04c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Compute difference in performance between the models\n",
    "diff = \"d_difference\"\n",
    "merged[diff] = merged[\"wer_base_ft\"] - merged[\"wer_base\"]\n",
    "merged[\"difference\"] = merged[\"wer_base_ft\"] - merged[\"wer_base\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "713c37cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create \"Gain Base-Large Whisper\" df and compute divergence\n",
    "base_baseft_gain_df = merged[['support', 'wer_base_ft', 'd_wer_base_ft', 't_value_base_ft', \\\n",
    "       'support_count_base_ft', 'length_base_ft', 't_value_base_ft'] \\\n",
    "       + [diff, \"difference\", \"wer_base\", \"t_value_base\"]]\n",
    "base_baseft_gain_df = base_baseft_gain_df.rename(columns={'length_base_ft':'length'})\n",
    "base_baseft_gain_df = base_baseft_gain_df.reset_index()\n",
    "\n",
    "fp_divergence_difference = FP_Divergence(base_baseft_gain_df, diff)\n",
    "diff_nr = fp_divergence_difference.getDivergence(th_redundancy=0.0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b5aa8e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Select meaningful columns \n",
    "sel = diff_nr.itemsets.values\n",
    "compare_performance = merged.loc[sel].sort_values(diff, ascending = False)\n",
    "cols = ['d_difference', 'wer_base', 'wer_base_ft', 'support', 't_value_base', 't_value_base_ft']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d08dd8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "## plot the distribution of the gain in performance\n",
    "list_diff_pos = list(compare_performance[compare_performance['d_difference'] <= 0.0].d_difference)\n",
    "list_diff_pos = [i * 100 for i in list_diff_pos]\n",
    "fig, ax = plt.subplots(figsize=(6, 4))\n",
    "sns.histplot(list_diff_pos, bins=10, kde=False, ax=ax, color='C01', palette=\"colorblind\")\n",
    "list_diff_neg = list(compare_performance[compare_performance['d_difference'] >= 0.0].d_difference)\n",
    "list_diff_neg = [i * 100 for i in list_diff_neg]\n",
    "sns.histplot(list_diff_neg, bins=5, kde=False, ax=ax, color='#83C4FA', palette=\"colorblind\")\n",
    "\n",
    "ax.set_xlabel(\"Gap in performance\", fontsize=28)\n",
    "ax.set_ylabel(r\"# Subgroups\", fontsize=28)\n",
    "plt.xticks(fontsize=20)\n",
    "plt.yticks(fontsize=20)\n",
    "plt.tight_layout()\n",
    "# plt.savefig(\"distribution_gain_whisper_base_base_ft.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e5b0b63",
   "metadata": {},
   "source": [
    "## Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d62583ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Compute meaningful statistics:\n",
    "diff_nr_0 = fp_divergence_difference.getDivergence(th_redundancy=None)\n",
    "\n",
    "# Percentage of itemsets for which performance are equal for the two model\n",
    "print(\"Equal\")\n",
    "print(round(100*(diff_nr_0.loc[(diff_nr_0[diff])==0].shape[0]/diff_nr_0.shape[0]),10))\n",
    "\n",
    "# Percentage of itemsets for which performance are lower for Whisper Large\n",
    "# (The higher the WER the lower the performance)\n",
    "print(\"Greater\")\n",
    "print(round(100*(diff_nr_0.loc[(diff_nr_0[diff])>0].shape[0]/diff_nr_0.shape[0]), 10))\n",
    "greater = False if round(100*(diff_nr_0.loc[(diff_nr_0[diff])>0].shape[0]/diff_nr_0.shape[0]), 10) == 0.0 else True\n",
    "    \n",
    "# Percentage of itemsets for which performance are greater for Whisper Large\n",
    "# (The lower the WER the greater the performance)\n",
    "print(\"Lower\")\n",
    "print(round(100*(diff_nr_0.loc[(diff_nr_0[diff])<0].shape[0]/diff_nr_0.shape[0]), 10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e88c1bee",
   "metadata": {},
   "source": [
    "## Gain > 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef24d645",
   "metadata": {},
   "outputs": [],
   "source": [
    "if greater:\n",
    "## Retrieve the data cohorts for which Whisper Large performs worse than Whisper Base\n",
    "pr = compare_performance[cols].head(20).reset_index()\n",
    "pr[\"support\"] = pr[\"support\"].round(2)\n",
    "pr[\"wer_large\"] = (pr[\"wer_large\"]*100).round(2)\n",
    "pr[\"wer_base\"] = (pr[\"wer_base\"]*100).round(2)\n",
    "pr[\"d_difference\"] = (pr[\"d_difference\"]*100).round(2)\n",
    "\n",
    "## Abbreviate itemset names for better visualization\n",
    "pr_l = pr.head(2).copy()\n",
    "pr_l['itemsets'] = pr_l['itemsets'].apply(lambda x: sortItemset(x, abbreviations))\n",
    "pr_l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e8d6eae",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Compute Shapley Values for a given itemset\n",
    "if greater and len(pr) > 0:\n",
    "    itemset_1 = pr.iloc[1].itemsets\n",
    "    itemset_shap = fp_divergence_difference.computeShapleyValue(itemset_1)\n",
    "    itemset_shap = {k:v*100 for k,v in itemset_shap.items()}\n",
    "    plotShapleyValue(shapley_values=abbreviateDict(itemset_shap, abbreviations), \n",
    "                    sizeFig=(2,2), labelsize=16, titlesize=16)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78643b89",
   "metadata": {},
   "source": [
    "## Gain < 0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22ab6b80",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Retrieve the data cohorts for which Whisper Base-Ft performs better than Whisper Base\n",
    "pr = compare_performance[cols][::-1].head(20).reset_index()\n",
    "pr[\"support\"] = pr[\"support\"].round(2)\n",
    "pr[\"wer_base_ft\"] = (pr[\"wer_base_ft\"]*100).round(2)\n",
    "pr[\"wer_base\"] = (pr[\"wer_base\"]*100).round(2)\n",
    "pr[\"d_difference\"] = (pr[\"d_difference\"]*100).round(2)\n",
    "\n",
    "## Abbreviate itemset names for better visualization\n",
    "pr_l = pr.head(2).copy()\n",
    "pr_l['itemsets'] = pr_l['itemsets'].apply(lambda x: sortItemset(x, abbreviations))\n",
    "pr_l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5789a239",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Compute Shapley Values for a given itemset\n",
    "if len(pr) > 0:\n",
    "    itemset_1 = pr.iloc[0].itemsets\n",
    "    itemset_shap = fp_divergence_difference.computeShapleyValue(itemset_1)\n",
    "    itemset_shap = {k:v*100 for k,v in itemset_shap.items()}\n",
    "    plotShapleyValue(shapley_values=abbreviateDict(itemset_shap, abbreviations), \n",
    "                    sizeFig=(2,2), labelsize=16, titlesize=16)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56da793b",
   "metadata": {},
   "source": [
    "## Gain = 0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ba6f6c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Retrieve the data cohorts for which Whisper Large performs equal to Whisper Base\n",
    "pr = merged.loc[ fp_divergence_difference.getDivergence(th_redundancy=0.0).itemsets.values][cols].reset_index()\n",
    "pr[\"support_large\"] = pr[\"support\"].round(2)\n",
    "pr[\"wer_large\"] = (pr[\"wer_large\"]*100).round(2)\n",
    "pr[\"wer_base\"] = (pr[\"wer_base\"]*100).round(2)\n",
    "pr[\"d_difference\"] = (pr[\"d_difference\"]*100).round(2)\n",
    "pr = pr.loc[abs(pr[\"d_difference\"])==0]\n",
    "pr = pr.sort_values(\"wer_large\").sort_values(\"wer_large\")\n",
    "\n",
    "## Abbreviate itemset names for better visualization\n",
    "pr_l = pr.head(2).copy()\n",
    "pr_l['itemsets'] = pr_l['itemsets'].apply(lambda x: sortItemset(x, abbreviations))\n",
    "pr_l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1b9caba",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Compute Shapley Values for a given itemset\n",
    "if len(pr) > 0:\n",
    "    itemset_1 = pr.iloc[0].itemsets\n",
    "    itemset_shap = fp_divergence_difference.computeShapleyValue(itemset_1)\n",
    "    itemset_shap = {k:v*100 for k,v in itemset_shap.items()}\n",
    "    plotShapleyValue(shapley_values=abbreviateDict(itemset_shap, abbreviations), \n",
    "                    sizeFig=(2,2), labelsize=16, titlesize=16)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de97dc30",
   "metadata": {},
   "source": [
    "## Global Shapley value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe40f477",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Compute the top-K global shapley values related to the gain in performance between Whisper Base and Whisper Base Ft\n",
    "global_item_divergence_wb_wbft = fp_divergence_difference.computeGlobalShapleyValue()\n",
    "\n",
    "K = 15\n",
    "topK_global_wb_wbft = {k:v for k,v in global_item_divergence_wb_wbft.items() \\\n",
    "                        if k in sorted(global_item_divergence_wb_wbft, \n",
    "                        key=lambda x: abs(global_item_divergence_wb_wbft[x]))[::-1][:K]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "626287ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Plot and Save the image \n",
    "sizeFig = (3.2,4)\n",
    "labelsize = 16\n",
    "titlesize = 16\n",
    "\n",
    "topK_global_wb_wbft_abbr = abbreviateDict(topK_global_wb_wbft, abbreviations)\n",
    "topK_global_wb_wbft_abbr = {k:v*100 for k,v in topK_global_wb_wbft_abbr.items()}\n",
    "name_fig = \"global_shapley_gain_wb_wbft.pdf\"\n",
    "plotShapleyValue(shapley_values=topK_global_wb_wbft_abbr, \\\n",
    "                sizeFig=sizeFig, labelsize=labelsize, titlesize=titlesize, \\\n",
    "                title=r\"$\\tilde{\\Delta}^g_{gain} WhisperB - WhisperB FT$\",\n",
    "                nameFig=name_fig, saveFig=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e8548cf",
   "metadata": {},
   "source": [
    "# Divergence difference Whisper Medium EN vs Whisper Medium Multilingual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47cc0fe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Compute the divergence for Whisper Base\n",
    "config = 'openai_whisper-medium'\n",
    "fp_divergence_i = fp_divergence_dict[config]\n",
    "FPdiv_wl = fp_divergence_i.getDivergence(th_redundancy=None).copy()\n",
    "wbase_m = FPdiv_wl.set_index(\"itemsets\")\n",
    "\n",
    "## Compute the divergence for Whisper Base EN\n",
    "config = 'openai_whisper-medium_en'\n",
    "fp_divergence_i = fp_divergence_dict[config]\n",
    "FPdiv_wb = fp_divergence_i.getDivergence(th_redundancy=None).copy()\n",
    "wbase = FPdiv_wb.set_index(\"itemsets\")\n",
    "\n",
    "## Merge the df\n",
    "merged = wbase.join(wbase_m, lsuffix='_base', rsuffix='_base_m')\n",
    "merged = merged.rename(columns={'support_base_m': 'support'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06740ff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Compute difference in performance between the models\n",
    "diff = \"d_difference\"\n",
    "merged[diff] = merged[\"wer_base_m\"] - merged[\"wer_base\"]\n",
    "merged[\"difference\"] = merged[\"wer_base_m\"] - merged[\"wer_base\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89c363a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create \"Gain Base-BaseM Whisper\" df and compute divergence\n",
    "base_basem_gain_df = merged[['support', 'wer_base_m', 'd_wer_base_m', 't_value_base_m', \\\n",
    "       'support_count_base_m', 'length_base_m', 't_value_base_m'] \\\n",
    "       + [diff, \"difference\", \"wer_base\", \"t_value_base\"]]\n",
    "base_basem_gain_df = base_basem_gain_df.rename(columns={'length_base_m':'length'})\n",
    "base_basem_gain_df = base_basem_gain_df.reset_index()\n",
    "\n",
    "fp_divergence_difference = FP_Divergence(base_basem_gain_df, diff)\n",
    "diff_nr = fp_divergence_difference.getDivergence(th_redundancy=0.0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19d8edcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Select meaningful columns \n",
    "sel = diff_nr.itemsets.values\n",
    "compare_performance = merged.loc[sel].sort_values(diff, ascending = False)\n",
    "cols = ['d_difference', 'wer_base', 'wer_base_m', 'support', 't_value_base', 't_value_base_m']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c225d55",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "## plot the distribution of the gain in performance\n",
    "list_diff_pos = list(compare_performance[compare_performance['d_difference'] <= 0.0].d_difference)\n",
    "list_diff_pos = [i * 100 for i in list_diff_pos]\n",
    "fig, ax = plt.subplots(figsize=(6, 4))\n",
    "sns.histplot(list_diff_pos, bins=2, kde=False, ax=ax, color='C01', palette=\"colorblind\")\n",
    "list_diff_neg = list(compare_performance[compare_performance['d_difference'] >= 0.0].d_difference)\n",
    "list_diff_neg = [i * 100 for i in list_diff_neg]\n",
    "sns.histplot(list_diff_neg, bins=9, kde=False, ax=ax, color='#83C4FA', palette=\"colorblind\")\n",
    "\n",
    "ax.set_xlabel(\"Gap in performance\", fontsize=28)\n",
    "ax.set_ylabel(r\"# Subgroups\", fontsize=28)\n",
    "plt.xticks(fontsize=20)\n",
    "plt.yticks(fontsize=20)\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"distribution_gain_whisper_medium_medium_m.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7fa7dec",
   "metadata": {},
   "source": [
    "## Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8067b10",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Compute meaningful statistics:\n",
    "diff_nr_0 = fp_divergence_difference.getDivergence(th_redundancy=None)\n",
    "\n",
    "# Percentage of itemsets for which performance are equal for the two model\n",
    "print(\"Equal\")\n",
    "print(round(100*(diff_nr_0.loc[(diff_nr_0[diff])==0].shape[0]/diff_nr_0.shape[0]),10))\n",
    "\n",
    "# Percentage of itemsets for which performance are lower for Whisper Large\n",
    "# (The higher the WER the lower the performance)\n",
    "print(\"Greater\")\n",
    "print(round(100*(diff_nr_0.loc[(diff_nr_0[diff])>0].shape[0]/diff_nr_0.shape[0]), 10))\n",
    "greater = False if round(100*(diff_nr_0.loc[(diff_nr_0[diff])>0].shape[0]/diff_nr_0.shape[0]), 10) == 0.0 else True\n",
    "    \n",
    "# Percentage of itemsets for which performance are greater for Whisper Large\n",
    "# (The lower the WER the greater the performance)\n",
    "print(\"Lower\")\n",
    "print(round(100*(diff_nr_0.loc[(diff_nr_0[diff])<0].shape[0]/diff_nr_0.shape[0]), 10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9a5abb1",
   "metadata": {},
   "source": [
    "## Gain > 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cb4fdd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Retrieve the data cohorts for which Whisper BaseM performs worse than Whisper Base\n",
    "pr = compare_performance[cols].head(20).reset_index()\n",
    "pr[\"support\"] = pr[\"support\"].round(2)\n",
    "pr[\"wer_base_m\"] = (pr[\"wer_base_m\"]*100).round(2)\n",
    "pr[\"wer_base\"] = (pr[\"wer_base\"]*100).round(2)\n",
    "pr[\"d_difference\"] = (pr[\"d_difference\"]*100).round(2)\n",
    "\n",
    "## Abbreviate itemset names for better visualization\n",
    "pr_l = pr.head(2).copy()\n",
    "pr_l['itemsets'] = pr_l['itemsets'].apply(lambda x: sortItemset(x, abbreviations))\n",
    "pr_l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea6cabb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Compute Shapley Values for a given itemset\n",
    "if len(pr) > 0:\n",
    "    itemset_1 = pr.iloc[1].itemsets\n",
    "    itemset_shap = fp_divergence_difference.computeShapleyValue(itemset_1)\n",
    "    itemset_shap = {k:v*100 for k,v in itemset_shap.items()}\n",
    "    plotShapleyValue(shapley_values=abbreviateDict(itemset_shap, abbreviations), \n",
    "                    sizeFig=(2,2), labelsize=16, titlesize=16)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e31d9d82",
   "metadata": {},
   "source": [
    "## Gain < 0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b002e90f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Retrieve the data cohorts for which Whisper BaseM performs better than Whisper Base\n",
    "pr = compare_performance[cols][::-1].head(20).reset_index()\n",
    "pr[\"support\"] = pr[\"support\"].round(2)\n",
    "pr[\"wer_base_m\"] = (pr[\"wer_base_m\"]*100).round(2)\n",
    "pr[\"wer_base\"] = (pr[\"wer_base\"]*100).round(2)\n",
    "pr[\"d_difference\"] = (pr[\"d_difference\"]*100).round(2)\n",
    "\n",
    "## Abbreviate itemset names for better visualization\n",
    "pr_l = pr.head(2).copy()\n",
    "pr_l['itemsets'] = pr_l['itemsets'].apply(lambda x: sortItemset(x, abbreviations))\n",
    "pr_l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b016996b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Compute Shapley Values for a given itemset\n",
    "if len(pr) > 0:\n",
    "    itemset_1 = pr.iloc[0].itemsets\n",
    "    itemset_shap = fp_divergence_difference.computeShapleyValue(itemset_1)\n",
    "    itemset_shap = {k:v*100 for k,v in itemset_shap.items()}\n",
    "    plotShapleyValue(shapley_values=abbreviateDict(itemset_shap, abbreviations), \n",
    "                    sizeFig=(2,2), labelsize=16, titlesize=16)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66970f16",
   "metadata": {},
   "source": [
    "## Gain = 0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6ee99d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Retrieve the data cohorts for which Whisper Large performs equal to Whisper Base\n",
    "pr = merged.loc[ fp_divergence_difference.getDivergence(th_redundancy=0.0).itemsets.values][cols].reset_index()\n",
    "pr[\"support_large\"] = pr[\"support\"].round(2)\n",
    "pr[\"wer_base_m\"] = (pr[\"wer_base_m\"]*100).round(2)\n",
    "pr[\"wer_base\"] = (pr[\"wer_base\"]*100).round(2)\n",
    "pr[\"d_difference\"] = (pr[\"d_difference\"]*100).round(2)\n",
    "pr = pr.loc[abs(pr[\"d_difference\"])==0]\n",
    "pr = pr.sort_values(\"wer_base_m\").sort_values(\"wer_base_m\")\n",
    "\n",
    "## Abbreviate itemset names for better visualization\n",
    "pr_l = pr.head(2).copy()\n",
    "pr_l['itemsets'] = pr_l['itemsets'].apply(lambda x: sortItemset(x, abbreviations))\n",
    "pr_l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4633d01",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Compute Shapley Values for a given itemset\n",
    "if len(pr) > 0:\n",
    "    itemset_1 = pr.iloc[0].itemsets\n",
    "    itemset_shap = fp_divergence_difference.computeShapleyValue(itemset_1)\n",
    "    itemset_shap = {k:v*100 for k,v in itemset_shap.items()}\n",
    "    plotShapleyValue(shapley_values=abbreviateDict(itemset_shap, abbreviations), \n",
    "                    sizeFig=(2,2), labelsize=16, titlesize=16)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86d6e27e",
   "metadata": {},
   "source": [
    "## Global Shapley value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af9f2e9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Compute the top-K global shapley values related to the gain in performance between Whisper Base and Whisper Base Ft\n",
    "global_item_divergence_wb_wbm = fp_divergence_difference.computeGlobalShapleyValue()\n",
    "\n",
    "K = 15\n",
    "topK_global_wb_wbm = {k:v for k,v in global_item_divergence_wb_wbm.items() \\\n",
    "                        if k in sorted(global_item_divergence_wb_wbm, \n",
    "                        key=lambda x: abs(global_item_divergence_wb_wbm[x]))[::-1][:K]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a7d5a89",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Plot and Save the image \n",
    "sizeFig = (3.2,4)\n",
    "labelsize = 16\n",
    "titlesize = 16\n",
    "\n",
    "topK_global_wb_wbm_abbr = abbreviateDict(topK_global_wb_wbm, abbreviations)\n",
    "topK_global_wb_wbm_abbr = {k:v*100 for k,v in topK_global_wb_wbm.items()}\n",
    "name_fig = \"global_shapley_gain_wb_wbft.pdf\"\n",
    "plotShapleyValue(shapley_values=topK_global_wb_wbm_abbr, \\\n",
    "                sizeFig=sizeFig, labelsize=labelsize, titlesize=titlesize, \\\n",
    "                title=r\"$\\tilde{\\Delta}^g_{gain} WhisperM_{EN} - WhisperM_{Multi}$\",\n",
    "                nameFig=name_fig, saveFig=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2e38d5a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "DivExplorer_FSC_IC.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 ('speech': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "313.76837158203125px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "vscode": {
   "interpreter": {
    "hash": "50f798c039f92e39594af06ec0119751541d975fa6ec3b2f5528645cd2e370ad"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
